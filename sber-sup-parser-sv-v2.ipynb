{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             Подключение библиотек\n",
    "# Отправка HTTP запросов и возврат ответов\n",
    "import requests\n",
    "# Обработка ответов в формате html\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# Работа с .json\n",
    "import json\n",
    "# Создание логов\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             Конфигурация\n",
    "\n",
    "# Папка проекта\n",
    "folderForResults = 'korchagin'\n",
    "# Имя лог-файла\n",
    "logFileName = 'picture.log'\n",
    "# Имя файла-результата\n",
    "outFileName = 'result.json'\n",
    "\n",
    "# URL ресурса\n",
    "resourceURL = 'https://www.imdb.com/'\n",
    "# URL страницы поиска\n",
    "searchPageURL = 'https://www.imdb.com/search/title'\n",
    "\n",
    "#     Фильтрация\n",
    "filters = {\n",
    "##     TITLE_TYPE\n",
    "##     May be: feature,tv_movie,tv_series,tv_special,tv_miniseries,documentary,video_game,short,video,tv_short\n",
    "\n",
    "    # 'title_type': \"feature,tv_short\",\n",
    "    \n",
    "##     RELEASE_DATE\n",
    "##     Format: YYYY-MM-DD, YYYY-MM, or YYYY\n",
    "##     Example: \"2000-01-01,2013-12-31\" or \"2000-01-01,\" or \",2013-12-31\"\n",
    "\n",
    "    # 'release_date': \"\",\n",
    "    \n",
    "##     GENRES\n",
    "##     May be:  Action,Adventure,Animation,Biography,Comedy,Crime,Documentary,Drama,Family,Fantasy,Film-Noir,Game-Show,History,Horror,Music,Musical,Mystery,News,Reality-TV,Romance,Sci-Fi,Sport,Talk-Show,Thriller,War,Western\n",
    "    'genres': \"Action,Adventure\",\n",
    "#     'genres': 'reality-tv,romance,talk-show,thriller',   \n",
    "    \n",
    "##     USER_RAITING\n",
    "##     Example: \"7.0,10.0\" or \"7.0,\" or \",5.0\"\n",
    "#     'user_rating': \"\"\n",
    "    \n",
    "##     COUNTRIES\n",
    "##     Abbreviated name from the list at the end of the notebook\n",
    "##     Example: \"ax,ad\"\n",
    "#       'countries': \"ru,gb,us\",\n",
    "    \n",
    "##     COUNT\n",
    "    'count': 250,\n",
    "    'start': 1\n",
    "}\n",
    "\n",
    "# СКОЛЬКО КАРТИН ОБРАБОТАТЬ\n",
    "desiredNumberOfImages = 1000\n",
    "# обработано в настоящий момент\n",
    "currentNumberOfPictures = 0\n",
    "\n",
    "# Настройка логов\n",
    "logging.basicConfig(handlers=[logging.FileHandler(logFileName, 'w', 'utf-8')], format='[%(levelname)s] : %(asctime)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запрос https://www.imdb.com/search/title/?genres=Action%2CAdventure&count=250&start=1 [0 / 1000]\n",
      "Запрос https://www.imdb.com/search/title/?genres=Action%2CAdventure&count=250&start=250 [250 / 1000]\n",
      "Запрос https://www.imdb.com/search/title/?genres=Action%2CAdventure&count=250&start=500 [500 / 1000]\n",
      "Запрос https://www.imdb.com/search/title/?genres=Action%2CAdventure&count=250&start=750 [750 / 1000]\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# 1. Отправляем запрос с фильтрами\n",
    "try:\n",
    "    # Результирующий массив\n",
    "    completedPictures = []\n",
    "    # Оборачиваем в цикл, чтобы обработать максимально разрешенные 250 картин\n",
    "    # \"Пока количество необх. картин < текущ. знач\n",
    "    while desiredNumberOfImages > len(completedPictures):\n",
    "        # Посылаем GET запрос, в ответ получаем html страничку с результатами поиска.\n",
    "        searchPage = requests.get(searchPageURL, params=filters)\n",
    "        logging.info(\"Запрос \" + searchPage.url)\n",
    "        print(\"Запрос \" + searchPage.url + \" [\" + str(currentNumberOfPictures) + \" / \" + str(desiredNumberOfImages) + \"]\")\n",
    "        if searchPage.status_code != 200:\n",
    "            # Если запрос пришел не с кодом \"без ошибок\", то вызываем исключение.\n",
    "            raise Exception(\"Запрос получения страницы поиска пришел с ошибкой. КОД \" + str(searchPage.status_code) + \".\")\n",
    "        # Теперь необходимо распарсить эту страничку и вытянуть нужное нам.\n",
    "        soup = bs(searchPage.text, 'html.parser')\n",
    "        # Проверим, нашлось ли чего по нашему фильтру\n",
    "        if soup.find(class_='desc').text.strip() == 'No results.':\n",
    "            raise Exception(\"Результаты с такими параметрами фильтрации не найдены: \" + json.dumps(filters))\n",
    "        # Еще проверим, а не все ли фильмы мы уже посмотрели, то есть других то больше нет.\n",
    "        if soup.find(class_='desc').text.strip() == str(len(completedPictures)) + \" titles.\":\n",
    "            break\n",
    "        logging.info(\"Объекты с параметрами фильтрации найдены.\")\n",
    "        # Найдем все тэги с классом \"lister-item mode-advanced\"\n",
    "        listOfWorks = soup.find_all(class_='lister-item mode-advanced')\n",
    "        # Так как элементов с классом \"lister-item mode-advanced\" много (ну или должно быть много)\n",
    "        # необходимо \"пройтись по каждому\", используем ЦИКЛ.\n",
    "        for product in listOfWorks:\n",
    "            # Если мы уже сохранили достаточно картин, то выходим.\n",
    "            if currentNumberOfPictures > desiredNumberOfImages:\n",
    "                break\n",
    "            # Теперь в каждом фильме нам нужно найти что-то конкретное, например НАЗВАНИЕ\n",
    "            # В скриншотах второго сообщения будет инфа, почему я выбрал именно этот блок, а так же как я его нашел, собственно\n",
    "            # И сразу маленькая деталь. Так как тег <a> (ссылка в html) идет без класса или другой идентификации \n",
    "            # (а таких ссылок даже у 1 фильма несколько)\n",
    "            productInfo = product.find('h3', class_='lister-item-header')\n",
    "            if productInfo is not None:\n",
    "                # ИМЯ\n",
    "                name = productInfo.find('a')\n",
    "                \n",
    "                # Переходим на страницу фильма для получения полной информации о нем\n",
    "                # Формируем ссылку, используя атрибут href тега <a>\n",
    "                logging.info(\"Сбор информации со страницы \" + resourceURL + name.attrs[\"href\"])\n",
    "                page = requests.get(resourceURL + name.attrs[\"href\"])\n",
    "                logging.info(\"- Статус ответа: \" + str(page.status_code)) # Если код 200 (см. протокол HTTP), то все ОК!\n",
    "                if page.status_code != 200:\n",
    "                    logging.critical(\"Запрос пришел с ошибкой. КОД \" + str(page.status_code))\n",
    "                    raise Exception(\"Запрос пришел с ошибкой. КОД \" + str(page.status_code))\n",
    "                soup = bs(page.text, 'html.parser')\n",
    "                \n",
    "                # ЖАНР\n",
    "                # Блоков класса \"see-more inline canwrap\" может быть несколько. Нам нужен тот, в котором есть \"Genres:\"\n",
    "                divs = soup.find_all(class_='see-more inline canwrap')\n",
    "                genres = []\n",
    "                for div in divs:\n",
    "                    if div.find('h4', class_='inline') and div.find('h4', class_='inline').text == 'Genres:':\n",
    "                        logging.info('- Жанр обнаружен')\n",
    "                        # Жанры выделены в отдельные ссылки (т.е. теги <a>), \n",
    "                        # находим их все а дальше складываем в массик genres\n",
    "                        # на всякий удаляем пробелы слева и справа от текста в ссылке\n",
    "                        geners_list = div.find_all('a')\n",
    "                        for genre in geners_list:\n",
    "                            genres.append(genre.text.strip()) \n",
    "                            \n",
    "                # РЕЙТИНГ\n",
    "                \n",
    "                ratings = soup.find_all(class_='ratings_wrapper')\n",
    "                if len(ratings) > 0:\n",
    "                    # Фильму простравлен рейтинг, находим оценку и записываем.\n",
    "#                     logging.info(\"- Есть рейтинг\") #UPD: НЕ ВСЕГДА www.imdb.com//title/tt8804038/\n",
    "                    # Зная, что \"ratings_wrapper\" на странице один, а метод возвращает массив объектов,\n",
    "                    # нам нужно взять самый первый и работать с ним\n",
    "                    ratings = ratings[0]\n",
    "                    # Ищем атрибут string, затем span, берем у последнего текст\n",
    "                    if ratings.find('strong'):\n",
    "                        ratings = float(ratings.find('strong').find('span').text)\n",
    "                        logging.info(\"- Есть рейтинг\")\n",
    "                    else:\n",
    "                        ratings = \"Фильм еще не имеет оценок\"\n",
    "                        logging.info(\"- \" + ratings)\n",
    "                else:\n",
    "                    # У фильма нет рейтинга. Вероятно, он еще не вышел или не был оценен.\n",
    "                    ratings = \"Фильм еще не имеет оценок\"\n",
    "                    logging.info(\"- \" + ratings)\n",
    "                    \n",
    "                # Топ каста (stars)\n",
    "                cast = \"\"\n",
    "                if soup.find('table', class_='cast_list'):\n",
    "                    cast = soup.find('table', class_='cast_list')\n",
    "                    if cast:\n",
    "                        # Если у фильма есть список актеров (гипотетически, он должен быть всегда)\n",
    "                        logging.info(\"- Список актеров присутствует\")\n",
    "                        # Я знаю, что таблица \"cast_list\" состоит из строк. \n",
    "                        # Найдем их.\n",
    "                        cast_rows = cast.find_all('tr')\n",
    "                        cast = []\n",
    "\n",
    "                        # Первая строка - информация, ее нужно пропустить\n",
    "                        for i in range(len(cast_rows[1:])):\n",
    "                            if cast_rows[i+1].find('a') and cast_rows[i+1].find('a').img.attrs[\"title\"]:\n",
    "                                cast.append(cast_rows[i+1].find('a').img.attrs[\"title\"])\n",
    "                    else:\n",
    "                        cast = \"Список актеров отсутствует\"\n",
    "                    \n",
    "                # Тип (сериал, фильм и т.д.)\n",
    "                type_film = \"Фильм\"\n",
    "                if soup.find(class_='seasons-and-year-nav'):\n",
    "                    # Ищем блок с классом, в котором располагаются ссылки на сезоны\n",
    "                    typeFilmDivision = soup.find(class_='seasons-and-year-nav')\n",
    "                    if typeFilmDivision.find('a'):\n",
    "                        # Если мы можем вытянуть номер последнего сезона (это всегда первая ссылка)\n",
    "                        # то прописываем его в скобках [N]\n",
    "                        type_film = \"Сериал [\" + typeFilmDivision.find('a').text + \"]\"\n",
    "                    else:\n",
    "                        type_film = \"Сериал\"\n",
    "                else: type_film = \"Фильм\"\n",
    "                logging.info(\"- Это \" + type_film)\n",
    "                \n",
    "                # Блоки Details, Box office, Technical specs\n",
    "                Details = []\n",
    "                # Находим div\n",
    "                if soup.find(id='titleDetails'):\n",
    "                    divisionDetails = soup.find(id='titleDetails')\n",
    "                    textFieldsOfDetails = divisionDetails.find_all(class_='txt-block')\n",
    "                    for textField in textFieldsOfDetails:\n",
    "                        if textField.find('h4') and textField.find('a') and textField.find('a').text != 'See more':\n",
    "                            headingOfDetail = textField.find('h4').text\n",
    "                            textOfDetail = textField.find('a').text\n",
    "                            if textField.find('a'):  # Вытягиваем ссылку на подробность\n",
    "                                Details.append({headingOfDetail.replace(\":\", \"\") : textOfDetail, 'link': textField.find('a').attrs[\"href\"]})\n",
    "                            else:\n",
    "                                Details.append({headingOfDetail.replace(\":\", \"\") : textOfDetail})\n",
    "                        elif textField.find('h4'):\n",
    "                            # Если у нас нет ссылки, то информация следует сразу за объявлением <div>.\n",
    "                            # Для того, чтобы достать эту информацию, необходимо получить строки\n",
    "                            # без пробелов и символов начала строки. В этом поможет метод \"stripped_strings\"\n",
    "                            # Экмпериментально доказано, что таким образом нужную информацию можно выловаить, если взять 2 эл-т.\n",
    "                            Details.append({textField.find('h4').text.replace(\":\", \"\") : list(textField.stripped_strings)[1]})\n",
    "                \n",
    "                #  Добавляем в массив результатов\n",
    "                completedPictures.append({'name': name.text, 'ratings': ratings, 'cast': cast, 'genres': genres, 'type': type_film, 'details': Details})\n",
    "                logging.info(\"ВЫПОЛНЕНО: \" + str(name.text))\n",
    "                currentNumberOfPictures += 1\n",
    "        filters['start'] = len(completedPictures)   \n",
    "    with open(outFileName, 'w', encoding='utf-8') as f:\n",
    "        # Записываем в файл результат, конвертированный в json\n",
    "        f.write(json.dumps(completedPictures, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "    logging.info(\"Информация записана в файл \" + str(outFileName))\n",
    "    logging.info(\"Записей обработано: \" + str(len(completedPictures)) + \"\\n\")\n",
    "    print(\"DONE\")\n",
    "            \n",
    "except Exception as e:\n",
    "    logging.error(e)\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIST OF COUNTRIES AND ABBREVIATIONS\n",
    "======\n",
    "\n",
    "| KODE | COUNTRY\n",
    "| :---: | :--- \n",
    "| af | Afghanistan |\n",
    "| ax | Åland Islands |\n",
    "| al | Albania |\n",
    "| dz | Algeria |\n",
    "| as | American Samoa |\n",
    "| ad | Andorra |\n",
    "| ao | Angola |\n",
    "| ai | Anguilla |\n",
    "| aq | Antarctica |\n",
    "| ag | Antigua and Barbuda |\n",
    "| ar | Argentina |\n",
    "| am | Armenia |\n",
    "| aw | Aruba |\n",
    "| au | Australia |\n",
    "| at | Austria |\n",
    "| az | Azerbaijan |\n",
    "| bs | Bahamas |\n",
    "| bh | Bahrain |\n",
    "| bd | Bangladesh |\n",
    "| bb | Barbados |\n",
    "| by | Belarus |\n",
    "| be | Belgium |\n",
    "| bz | Belize |\n",
    "| bj | Benin |\n",
    "| bm | Bermuda |\n",
    "| bt | Bhutan |\n",
    "| bo | Bolivia |\n",
    "| bq | Bonaire, Sint Eustatius and Saba |\n",
    "| ba | Bosnia and Herzegovina |\n",
    "| bw | Botswana |\n",
    "| bv | Bouvet Island |\n",
    "| br | Brazil |\n",
    "| io | British Indian Ocean Territory |\n",
    "| vg | British Virgin Islands |\n",
    "| bn | Brunei Darussalam |\n",
    "| bg | Bulgaria |\n",
    "| bf | Burkina Faso |\n",
    "| bumm | Burma |\n",
    "| bi | Burundi |\n",
    "| kh | Cambodia |\n",
    "| cm | Cameroon |\n",
    "| ca | Canada |\n",
    "| cv | Cape Verde |\n",
    "| ky | Cayman Islands |\n",
    "| cf | Central African Republic |\n",
    "| td | Chad |\n",
    "| cl | Chile |\n",
    "| cn | China |\n",
    "| cx | Christmas Island |\n",
    "| cc | Cocos (Keeling) Islands |\n",
    "| co | Colombia |\n",
    "| km | Comoros |\n",
    "| cg | Congo |\n",
    "| ck | Cook Islands |\n",
    "| cr | Costa Rica |\n",
    "| ci | Côte d'Ivoire |\n",
    "| hr | Croatia |\n",
    "| cu | Cuba |\n",
    "| cy | Cyprus |\n",
    "| cz | Czech Republic |\n",
    "| cshh | Czechoslovakia |\n",
    "| cd | Democratic Republic of the Congo |\n",
    "| dk | Denmark |\n",
    "| dj | Djibouti |\n",
    "| dm | Dominica |\n",
    "| do | Dominican Republic |\n",
    "| ddde | East Germany |\n",
    "| ec | Ecuador |\n",
    "| eg | Egypt |\n",
    "| sv | El Salvador |\n",
    "| gq | Equatorial Guinea |\n",
    "| er | Eritrea |\n",
    "| ee | Estonia |\n",
    "| et | Ethiopia |\n",
    "| fk | Falkland Islands |\n",
    "| fo | Faroe Islands |\n",
    "| yucs | Federal Republic of Yugoslavia |\n",
    "| fm | Federated States of Micronesia |\n",
    "| fj | Fiji |\n",
    "| fi | Finland |\n",
    "| fr | France |\n",
    "| gf | French Guiana |\n",
    "| pf | French Polynesia |\n",
    "| tf | French Southern Territories |\n",
    "| ga | Gabon |\n",
    "| gm | Gambia |\n",
    "| ge | Georgia |\n",
    "| de | Germany |\n",
    "| gh | Ghana |\n",
    "| gi | Gibraltar |\n",
    "| gr | Greece |\n",
    "| gl | Greenland |\n",
    "| gd | Grenada |\n",
    "| gp | Guadeloupe |\n",
    "| gu | Guam |\n",
    "| gt | Guatemala |\n",
    "| gg | Guernsey |\n",
    "| gn | Guinea |\n",
    "| gw | Guinea-Bissau |\n",
    "| gy | Guyana |\n",
    "| ht | Haiti |\n",
    "| hm | Heard Island and McDonald Islands |\n",
    "| va | Holy See (Vatican City State) |\n",
    "| hn | Honduras |\n",
    "| hk | Hong Kong |\n",
    "| hu | Hungary |\n",
    "| is | Iceland |\n",
    "| in | India |\n",
    "| id | Indonesia |\n",
    "| ir | Iran |\n",
    "| iq | Iraq |\n",
    "| ie | Ireland |\n",
    "| im | Isle of Man |\n",
    "| il | Israel |\n",
    "| it | Italy |\n",
    "| jm | Jamaica |\n",
    "| jp | Japan |\n",
    "| je | Jersey |\n",
    "| jo | Jordan |\n",
    "| kz | Kazakhstan |\n",
    "| ke | Kenya |\n",
    "| ki | Kiribati |\n",
    "| xko | Korea |\n",
    "| xkv | Kosovo |\n",
    "| kw | Kuwait |\n",
    "| kg | Kyrgyzstan |\n",
    "| la | Laos |\n",
    "| lv | Latvia |\n",
    "| lb | Lebanon |\n",
    "| ls | Lesotho |\n",
    "| lr | Liberia |\n",
    "| ly | Libya |\n",
    "| li | Liechtenstein |\n",
    "| lt | Lithuania |\n",
    "| lu | Luxembourg |\n",
    "| mo | Macao |\n",
    "| mg | Madagascar |\n",
    "| mw | Malawi |\n",
    "| my | Malaysia |\n",
    "| mv | Maldives |\n",
    "| ml | Mali |\n",
    "| mt | Malta |\n",
    "| mh | Marshall Islands |\n",
    "| mq | Martinique |\n",
    "| mr | Mauritania |\n",
    "| mu | Mauritius |\n",
    "| yt | Mayotte |\n",
    "| mx | Mexico |\n",
    "| md | Moldova |\n",
    "| mc | Monaco |\n",
    "| mn | Mongolia |\n",
    "| me | Montenegro |\n",
    "| ms | Montserrat |\n",
    "| ma | Morocco |\n",
    "| mz | Mozambique |\n",
    "| mm | Myanmar |\n",
    "| na | Namibia |\n",
    "| nr | Nauru |\n",
    "| np | Nepal |\n",
    "| nl | Netherlands |\n",
    "| an | Netherlands Antilles |\n",
    "| nc | New Caledonia |\n",
    "| nz | New Zealand |\n",
    "| ni | Nicaragua |\n",
    "| ne | Niger |\n",
    "| ng | Nigeria |\n",
    "| nu | Niue |\n",
    "| nf | Norfolk Island |\n",
    "| kp | North Korea |\n",
    "| vdvn | North Vietnam |\n",
    "| mp | Northern Mariana Islands |\n",
    "| no | Norway |\n",
    "| om | Oman |\n",
    "| pk | Pakistan |\n",
    "| pw | Palau |\n",
    "| xpi | Palestine |\n",
    "| ps | Palestinian Territory |\n",
    "| pa | Panama |\n",
    "| pg | Papua New Guinea |\n",
    "| py | Paraguay |\n",
    "| pe | Peru |\n",
    "| ph | Philippines |\n",
    "| pl | Poland |\n",
    "| pt | Portugal |\n",
    "| pn | Pitcairn |\n",
    "| pr | Puerto Rico |\n",
    "| qa | Qatar |\n",
    "| mk | Republic of Macedonia |\n",
    "| re | Réunion |\n",
    "| ro | Romania |\n",
    "| ru | Russia |\n",
    "| rw | Rwanda |\n",
    "| bl | Saint Barthélemy |\n",
    "| sh | Saint Helena |\n",
    "| kn | Saint Kitts and Nevis |\n",
    "| lc | Saint Lucia |\n",
    "| mf | Saint Martin (French part) |\n",
    "| pm | Saint Pierre and Miquelon |\n",
    "| vc | Saint Vincent and the Grenadines |\n",
    "| ws | Samoa |\n",
    "| sm | San Marino |\n",
    "| st | Sao Tome and Principe |\n",
    "| sa | Saudi Arabia |\n",
    "| sn | Senegal |\n",
    "| rs | Serbia |\n",
    "| csxx | Serbia and Montenegro |\n",
    "| sc | Seychelles |\n",
    "| xsi | Siam |\n",
    "| sl | Sierra Leone |\n",
    "| sg | Singapore |\n",
    "| sk | Slovakia |\n",
    "| si | Slovenia |\n",
    "| sb | Solomon Islands |\n",
    "| so | Somalia |\n",
    "| za | South Africa |\n",
    "| gs | South Georgia and the South Sandwich Islands |\n",
    "| kr | South Korea |\n",
    "| suhh | Soviet Union |\n",
    "| es | Spain |\n",
    "| lk | Sri Lanka |\n",
    "| sd | Sudan |\n",
    "| sr | Suriname |\n",
    "| sj | Svalbard and Jan Mayen |\n",
    "| sz | Swaziland |\n",
    "| se | Sweden |\n",
    "| ch | Switzerland |\n",
    "| sy | Syria |\n",
    "| tw | Taiwan |\n",
    "| tj | Tajikistan |\n",
    "| tz | Tanzania |\n",
    "| th | Thailand |\n",
    "| tl | Timor-Leste |\n",
    "| tg | Togo |\n",
    "| tk | Tokelau |\n",
    "| to | Tonga |\n",
    "| tt | Trinidad and Tobago |\n",
    "| tn | Tunisia |\n",
    "| tr | Turkey |\n",
    "| tm | Turkmenistan |\n",
    "| tc | Turks and Caicos Islands |\n",
    "| tv | Tuvalu |\n",
    "| vi | U.S. Virgin Islands |\n",
    "| ug | Uganda |\n",
    "| ua | Ukraine |\n",
    "| ae | United Arab Emirates |\n",
    "| gb | United Kingdom |\n",
    "| us | United States |\n",
    "| um | United States Minor Outlying Islands |\n",
    "| uy | Uruguay |\n",
    "| uz | Uzbekistan |\n",
    "| vu | Vanuatu |\n",
    "| ve | Venezuela |\n",
    "| vn | Vietnam |\n",
    "| wf | Wallis and Futuna |\n",
    "| xwg | West Germany |\n",
    "| eh | Western Sahara |\n",
    "| ye | Yemen |\n",
    "| xyu | Yugoslavia |\n",
    "| zrcd | Zaire |\n",
    "| zm | Zambia |\n",
    "| zw | Zimbabwe |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
